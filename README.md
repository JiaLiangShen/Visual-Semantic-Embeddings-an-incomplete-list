# Visual Semantic Embeddings and Text-Image Retrieval: an incomplete list

## Conferences
### NIPS 2013
**DeViSE: A Deep Visual-Semantic Embedding Model.**
*Andrea Frome, Greg S. Corrado, Jonathon Shlens, Samy Bengio, Jeffrey Dean, Marc’Aurelio Ranzato, Tomas Mikolov.*
[[paper]](https://papers.nips.cc/paper/5204-devise-a-deep-visual-semantic-embedding-model.pdf)

### NIPS 2014 Deep Learning Workshop
**Unifying Visual-Semantic Embeddings with Multimodal Neural Language Models.**
*Ryan Kiros, Ruslan Salakhutdinov, Richard S. Zemel.*
[[paper]](https://arxiv.org/pdf/1411.2539.pdf)
[[code]](https://github.com/ryankiros/visual-semantic-embedding)(Theano)

### CVPR 2015
**Deep Visual-Semantic Alignments for Generating Image Descriptions.**
*Andrej Karpathy, Li Fei-Fei.*
[[paper]](https://cs.stanford.edu/people/karpathy/cvpr2015.pdf)

**Deep Correlation for Matching Images and Text.**
*Fei Yan, Krystian Mikolajczyk.*
[[paper]](http://openaccess.thecvf.com/content_cvpr_2015/papers/Yan_Deep_Correlation_for_2015_CVPR_paper.pdf)

### ICLR 2016
**ORDER-EMBEDDINGS OF IMAGES AND LANGUAGE.**
*Ivan Vendrov, Ryan Kiros, Sanja Fidler, Raquel Urtasun.*
[[paper]](https://arxiv.org/pdf/1511.06361.pdf)

### CVPR 2016
**Learning Deep Structure-Preserving Image-Text Embeddings.**
*Liwei Wang, Yin Li, Svetlana Lazebnik.*
[[paper]](http://slazebni.cs.illinois.edu/publications/cvpr16_structure.pdf)

### CVPR 2017
**Learning a Deep Embedding Model for Zero-Shot Learning.**
*Li Zhang, Tao Xiang, Shaogang Gong.*
[[paper]](https://arxiv.org/pdf/1611.05088.pdf)
[[code]](https://github.com/lzrobots/DeepEmbeddingModel_ZSL)(TF)

**Deep Visual-Semantic Quantization for Efficient Image Retrieval.**
*Yue Cao, Mingsheng Long, Jianmin Wang, Shichen Liu.*
[[paper]](http://openaccess.thecvf.com/content_cvpr_2017/papers/Cao_Deep_Visual-Semantic_Quantization_CVPR_2017_paper.pdf)

**Dual Attention Networks for Multimodal Reasoning and Matching.**
*Hyeonseob Nam, Jung-Woo Ha, Jeonghee Kim.*
[[paper]](http://openaccess.thecvf.com/content_cvpr_2017/papers/Nam_Dual_Attention_Networks_CVPR_2017_paper.pdf)

### ICCV 2017
**Sampling Matters in Deep Embedding Learning.**
*Chao-Yuan Wu, R. Manmatha, Alexander J. Smola, Philipp Krähenbühl.*
[[paper]](https://arxiv.org/pdf/1706.07567.pdf)
[[zhihu discussion]](https://www.zhihu.com/question/61748966)

**Learning Robust Visual-Semantic Embeddings.**
*Yao-Hung Hubert Tsai, Liang-Kang Huang, Ruslan Salakhutdinov.*
[[paper]](http://openaccess.thecvf.com/content_ICCV_2017/papers/Tsai_Learning_Robust_Visual-Semantic_ICCV_2017_paper.pdf)

**Hierarchical Multimodal LSTM for Dense Visual-Semantic Embedding.**
*Zhenxing Niu, Mo Zhou, Le Wang, Xinbo Gao, Gang Hua.*
[[paper]](http://openaccess.thecvf.com/content_ICCV_2017/papers/Niu_Hierarchical_Multimodal_LSTM_ICCV_2017_paper.pdf)

**Learning a Recurrent Residual Fusion Network for Multimodal Matching.**
*Yu Liu, Yanming Guo, Erwin M. Bakker, Michael S. Lew.*
[[paper]](http://openaccess.thecvf.com/content_ICCV_2017/papers/Liu_Learning_a_Recurrent_ICCV_2017_paper.pdf)

### AAAI 2018
**VSE-ens: Visual-Semantic Embeddings with Efficient Negative Sampling.**
*Guibing Guo, Songlin Zhai, Fajie Yuan, Yuan Liu, Xingwei Wang.*
[[paper]](https://arxiv.org/pdf/1801.01632.pdf)

**Incorporating GAN for Negative Sampling in Knowledge Representation Learning.**
*Peifeng Wang, Shuangyin Li, Rong pan.*
[[paper]](https://arxiv.org/pdf/1809.11017.pdf)

### WACV 2018
**Fast Self-Attentive Multimodal Retrieval.**
*Jônatas Wehrmann, Maurício Armani Lopes, Martin D More, Rodrigo C. Barros.*
[[paper]](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8354311&tag=1)
[[code]](https://github.com/jwehrmann/seam-retrieval)(PyTorch)

### CVPR 2018
**End-to-end Convolutional Semantic Embeddings.**
*Quanzeng You, Zhengyou Zhang, Jiebo Luo.*
[[paper]](https://ai.tencent.com/ailab/media/publications/cvpr/End-to-end_Convolutional_Semantic_Embeddings.pdf)
 
**Bidirectional Retrieval Made Simple.**
*Jonatas Wehrmann, Rodrigo C. Barros.*
[[paper]](http://openaccess.thecvf.com/content_cvpr_2018/papers/Wehrmann_Bidirectional_Retrieval_Made_CVPR_2018_paper.pdf)
[[code]](https://github.com/jwehrmann/chain-vse)(PyTorch)

### ACL 2018
**Illustrative Language Understanding: Large-Scale Visual Grounding with Image Search.**
*Jamie Kiros, William Chan, Geoffrey Hinton.*
[[paper]](https://aclweb.org/anthology/P18-1085)

### COLING 2018
**Learning Visually-Grounded Semantics from Contrastive Adversarial Samples.**
*Haoyue Shi, Jiayuan Mao, Tete Xiao, Yuning Jiang, Jian Sun.*
[[paper]](https://aclweb.org/anthology/C18-1315)
[[code]](https://github.com/ExplorerFreda/VSE-C)(PyTorch)

### BMVC 2018
**VSE++: Improving Visual-Semantic Embeddings with Hard Negatives.**
*Fartash Faghri, David J. Fleet, Jamie Ryan Kiros, Sanja Fidler.*
[[paper]](https://arxiv.org/pdf/1707.05612.pdf)
[[code]](https://github.com/fartashf/vsepp)(PyTorch)

### ECCV 2018
**An Adversarial Approach to Hard Triplet Generation.**
*Yiru Zhao, Zhongming Jin, Guo-jun Qi, Hongtao Lu, Xian-sheng Hua.*
[[paper]](http://openaccess.thecvf.com/content_ECCV_2018/papers/Yiru_Zhao_A_Principled_Approach_ECCV_2018_paper.pdf)

**Conditional Image-Text Embedding Networks.**
*Bryan A. Plummer, Paige Kordas, M. Hadi Kiapour, Shuai Zheng, Robinson Piramuthu, Svetlana Lazebnik.*
[[paper]](https://arxiv.org/pdf/1711.08389.pdf)

**Visual-Semantic Alignment Across Domains Using a Semi-Supervised Approach.**
*Angelo Carraggi, Marcella Cornia, Lorenzo Baraldi, Rita Cucchiara.*
[[paper]](http://openaccess.thecvf.com/content_ECCVW_2018/papers/11134/Carraggi_Visual-Semantic_Alignment_Across_Domains_Using_a_Semi-Supervised_Approach_ECCVW_2018_paper.pdf)

**Stacked Cross Attention for Image-Text Matching.**
*Kuang-Huei Lee, Xi Chen, Gang Hua, Houdong Hu, Xiaodong He.*
[[paper]](https://eccv2018.org/openaccess/content_ECCV_2018/papers/Kuang-Huei_Lee_Stacked_Cross_Attention_ECCV_2018_paper.pdf)

**CurriculumNet: Weakly Supervised Learning from Large-Scale Web Images.**
*Sheng Guo, Weilin Huang, Haozhi Zhang, Chenfan Zhuang, Dengke Dong, Matthew R. Scott, Dinglong Huang.*
[[paper]](http://openaccess.thecvf.com/content_ECCV_2018/papers/Sheng_Guo_CurriculumNet_Learning_from_ECCV_2018_paper.pdf)
[[code]](https://github.com/MalongTech/research-curriculumnet)(Caffe)

### CVPR 2019
**Unified Visual-Semantic Embeddings: Bridging Vision and Language with Structured Meaning Representations.**
*Hao Wu, Jiayuan Mao, Yufeng Zhang, Yuning Jiang, Lei Li, Weiwei Sun1, Wei-Ying Ma.*
[[paper]](https://arxiv.org/pdf/1904.05521.pdf)

**Engaging Image Captioning via Personality.**
*Kurt Shuster, Samuel Humeau, Hexiang Hu, Antoine Bordes, Jason Weston.*
[[paper]](https://arxiv.org/pdf/1810.10665.pdf)

**Polysemous Visual-Semantic Embedding for Cross-Modal Retrieval.**
*Yale Song, Mohammad Soleymani.*
[[paper]](https://arxiv.org/pdf/1906.04402.pdf)
 
**Composing Text and Image for Image Retrieval - An Empirical Odyssey.**
*Nam Vo, Lu Jiang, Chen Sun, Kevin Murphy, Li-Jia Li, Li Fei-Fei, James Hays.*
[[paper]](https://arxiv.org/pdf/1812.07119.pdf)

### ICCV 2019
**Visual Semantic Reasoning for Image-Text Matching.**
*Kunpeng Li, Yulun Zhang, Kai Li, Yuanyuan Li, Yun Fu.*
[[paper]](https://arxiv.org/pdf/1909.02701.pdf)

**Adversarial Representation Learning for Text-to-Image Matching.**
*Nikolaos Sarafianos, Xiang Xu, Ioannis A. Kakadiaris.*
[[paper]](https://arxiv.org/pdf/1908.10534.pdf)

**CAMP: Cross-Modal Adaptive Message Passing for Text-Image Retrieval.**
*Zihao Wang, Xihui Liu, Hongsheng Li, Lu Sheng, Junjie Yan, Xiaogang Wang, Jing Shao.*
[[paper]](https://arxiv.org/pdf/1909.05506.pdf)

### EMNLP 2019
**Unsupervised Discovery of Multimodal Links in Multi-Image, Multi-Sentence Documents.**
*Jack Hessel, Lillian Lee, David Mimno.*
[[paper]](https://arxiv.org/pdf/1904.07826.pdf)
[[code]](https://github.com/jmhessel/multi-retrieval)

### AAAI 2020
**HAL: Improved Text-Image Matching by Mitigating Visual Semantic Hubs.**
*Fangyu Liu, Rongtian Ye, Xun Wang, Shuaipeng Li.*
[[paper]](https://arxiv.org/pdf/1911.10097v1.pdf)
[[code]](https://github.com/hardyqr/HAL)

**Ladder Loss for Coherent Visual-Semantic Embedding.**
*Mo Zhou, Zhenxing Niu, Le Wang, Zhanning Gao, Qilin Zhang, Gang Hua.*
[[paper]](https://arxiv.org/pdf/1911.07528.pdf)

**Expressing Objects just like Words: Recurrent Visual Embedding for Image-Text Matching.** 
*Tianlang Chen, Jiebo Luo.*
[[paper]](https://arxiv.org/pdf/2002.08510.pdf)

## Journals
### Machine Learning 2010
**Large scale image annotation: learning to rank with joint word-image embeddings.**
*Jason Weston, Samy Bengio, Nicolas Usunier.*
[[paper]](https://link.springer.com/content/pdf/10.1007%2Fs10994-010-5198-3.pdf)

### IPAMI 2019 
**Learning Two-Branch Neural Networks for Image-Text Matching Tasks.**
*Liwei Wang, Yin Li, Jing Huang, Svetlana Lazebnik.*
[[paper]](https://arxiv.org/pdf/1704.03470.pdf)
[[code]](https://github.com/lwwang/Two_branch_network)(TF)
